

### 南昌人社项目实施记录



#### 事有轻重缓急，先做重要的事情

##### 性能压力测试

找一张最大的库表进行全量同步的性能压力测试，测出现场环境下的最大同步效率（行/秒）。

1. 并行入库，找出可以稳定运行的最优值。
2. 并行抽取
3. 集群模式

目的：把所有可能的问题，提前压测出来，比如：机器内存不足、数据库并行入库能力差等等。

##### **收集库表信息**

1. 总共多少张表？
2. 每张表的索引列是什么？
3. 有时间戳的表有多少个？
4. 有自增ID的表有多少个？
5. 即没有时间戳，也没有自增ID的表有多少个？
6. 每张表需要全量同步的记录数是多少？

目的：提前确定每一张表的全量同步方式，估算完成同步所需的累计时间，管理用户预期。



------

#### 现场SQL语句优化

将源表AC08的数据过滤后同步至目标端（需要关联查询SBZX.wy_ab01_369900），目前执行的SQL语句如下：

```SQL for OceanBase
SELECT T.* FROM
(
    SELECT
    "AAZ648", "AAZ686", "AAC001", "AAE002", "AAE003", "AAE140", "AAA115", "AAE793", "AAE794", "AAC066"
    , "AAC313", "AAC314", "AAE737", "AAB001", "AAB019", "AAB365", "AAB033", "AAE745", "AAC040", "AAE180"
    , "AAB121", "AAE795", "AAE871", "AAE020", "AAE021", "AAE022", "AAE023", "AAE056", "AAE026", "AAE828"
    , "AIC380", "AAE834", "AAE845", "AAE844", "AAB191", "AAE080", "AAE081", "AAE082", "AAE083", "AAE057"
    , "AAE086", "AAE202", "AAA042", "AAA043", "AAA041", "AAA045", "AAZ615", "AAZ616", "AAE061", "AAZ625"
    , "AAZ223", "AAA093", "AAZ061", "AAE108", "AAE150", "AAE066", "AAE741", "AAB301", "AAB299", "AAE729"
    , "AAE819", "AAE820", "AAE796", "AAE797", "AAE798", "AAE799", "AAE800", "AAE792", "AAE748", "AAE822"
    , "AAZ631", "AAZ650", "AAC323", "AAZ159", "AAE013", "AAZ649", "AAE860", "AAE859", "AAE011", "AAZ692"
    , "AAE036", "AAB034", "AAB360", "AAB359", "AAF018", "AAA431", "AAZ673", "AAA027", "AAA508", "AAA350"
    , "AAE784", "AAE785", "AAE786", "AAE787", "AAE788", "AAE789", "AAE790", "AAE791", "AAE836", "AAE837"
    , "AAE838", "AAE839", "AAE840", "AAE841", "AAE842", "AAE843", "AAE887", "AAE888", "AAC028"
    , SUBSTR("AAA027", 0, 4) AS AAA027_STR
    FROM "EINP_COLLECTION"."AC08"
    WHERE AAZ648 >= ? and AAZ648 < ?
) t
WHERE 
    t.AAA027_STR = '3601'
  	or t.aab001 in (select aab001 from SBZX.wy_ab01_369900 where substr(aab301,0,4) = '3601');
```

**数据库模式：**

- "EINP_COLLECTION"
- SBZX

**库表：**

- "EINP_COLLECTION"."AC08"
- SBZX.wy_ab01_369900

 **子查询和别名t**

​	内层查询是一个子查询，它选择模式 "EINP_COLLECTION" 中的表 "AC08"特定的列，并对列 "AAA027" 应用 SUBSTR 函数（将结果命名为 AAA027_STR）。这个子查询的结果被赋予别名 t。

 **外层查询和别T**

​	外层查询从子查询 t 中选择所有列（T.*），并进一步过滤结果。

 **过滤条件**

​	外层查询的 WHERE 子句包括两个过滤条件，使用 OR 操作符连接：

> t.AAA027_STR = '3601'
>
> t.aab001 in (select aab001 from SBZX.wy_ab01_369900 where substr(aab301,0,4) = '3601')

<u>上面的SQL语句，没有必要嵌套子查询。使用子查询会生成中间结果集，存储和处理这些结果集会增加内存和I/O负载。</u>
 

<u>去掉子查询后，简化为：</u>

```SQL for OceanBase
SELECT
  "AAZ648", "AAZ686", "AAC001", "AAE002", "AAE003", "AAE140", "AAA115", "AAE793", "AAE794", "AAC066",
  "AAC313", "AAC314", "AAE737", "AAB001", "AAB019", "AAB365", "AAB033", "AAE745", "AAC040", "AAE180",
  "AAB121", "AAE795", "AAE871", "AAE020", "AAE021", "AAE022", "AAE023", "AAE056", "AAE026", "AAE828",
  "AIC380", "AAE834", "AAE845", "AAE844", "AAB191", "AAE080", "AAE081", "AAE082", "AAE083", "AAE057",
  "AAE086", "AAE202", "AAA042", "AAA043", "AAA041", "AAA045", "AAZ615", "AAZ616", "AAE061", "AAZ625",
  "AAZ223", "AAA093", "AAZ061", "AAE108", "AAE150", "AAE066", "AAE741", "AAB301", "AAB299", "AAE729",
  "AAE819", "AAE820", "AAE796", "AAE797", "AAE798", "AAE799", "AAE800", "AAE792", "AAE748", "AAE822",
  "AAZ631", "AAZ650", "AAC323", "AAZ159", "AAE013", "AAZ649", "AAE860", "AAE859", "AAE011", "AAZ692",
  "AAE036", "AAB034", "AAB360", "AAB359", "AAF018", "AAA431", "AAZ673", "AAA027", "AAA508", "AAA350",
  "AAE784", "AAE785", "AAE786", "AAE787", "AAE788", "AAE789", "AAE790", "AAE791", "AAE836", "AAE837",
  "AAE838", "AAE839", "AAE840", "AAE841", "AAE842", "AAE843", "AAE887", "AAE888", "AAC028",
  SUBSTR("AAA027", 0, 4)
FROM "EINP_COLLECTION"."AC08"
WHERE
  AAZ648 >= ? AND AAZ648 < ?
  AND (
    SUBSTR("AAA027", 0, 4) = '3601'
    OR AAB001 IN (
      SELECT aab001
      FROM SBZX.wy_ab01_369900
      WHERE SUBSTR(aab301, 0, 4) = '3601'
    )
  );
```

简化后的查询避免了中间结果集的生成，减少了内存和I/O的使用。



------

#### 现场实施记录

**原始需求**

源端数据库信息： 

OceanBase 3.2.3.3 (r110020022023092816-168c43d700d4e0d58037d28240081b22f274ddcd)(Built Sep 28 2023 16:39:21) 

目标端数据库信息：

OceanBase3.2.4.1 (r101000052023010822-346aa35c32e99d1b82d713f75f0072c45bdf7aab)(Built Jan 8 2023 22:54:29)

同步任务：在从源端表AC08做全量数据同步至目标端时，需要关联查询wy_ab01_369900和ac02两张表，以期从AC08表中获取到符合业务条件的数据。

**现场流程图如下，如下图所示：**

![image-20240611084029369](_media\南昌人社\ETL_全流程图.png)

------------------------------------------------------------------------------------

**表格记录生成组件AC08_AAZ648负责配置分批入库的数据范围，如下图所示：**

![image-20240611084152427](_media\南昌人社\ETL_表格记录生成1.png)

![image-20240611084159989](_media\南昌人社\ETL_表格记录生成2.png)

**SQL查询组件负责分批从前一个组件中拿到数据进行查询，如下图所示：**

![image-20240611084224861](_media\南昌人社\ETL_SQL查询.png)

**入库组件配置，如下图所示：**

![image-20240611084252475](_media\南昌人社\ETL_数据库记录插入.png)

**入库时采取对主键哈希区域分区方式进行多线程并行入库，如下图所示：**

![image-20240611084322296](_media\南昌人社\ETL_分区方法.png)

![image-20240611084328925](_media\南昌人社\ETL_选择一个分区模式.png)

![image-20240611084400443](_media\南昌人社\ETL_标准分区模式AAZ648.png)



------

#### 如何使用Nifi完成相同的业务场景

**为了方便演示，将子查询中的110列简化为以下4列：**

1. AAB001：过滤条件（两个库表里都有这个字段）

2. AAC301：过滤条件（两个库表里都有这个字段）

3. SUBSTR(AAA027, 0, 4) AS AAA027_STR：过滤条件（库表"AC08"中的字段）

4. AAZ648：分区列（库表"AC08"中的字段）

5. 其他列，省略（库表"AC08"中的字段）

   

**使用Nifi（自动分区）、mysql（语法有不同之处）演示上面的业务场景：**

```
SELECT AAB001,AAZ648, AAC301, SUBSTR(AAA027, 1, 4) FROM testdb.AC08
WHERE
	SUBSTR(AAA027, 1, 4) = '3601'
 	OR 
 	aab001 in (select aab001 from testdb.wy_ab01_369900 where substr(aab301,1,4) = '3601');
```



![image-20240611021001273](_media\南昌人社\南昌人社_nifi画布.png)

![image-20240611023844144](_media\南昌人社\南昌人社_nifi画布_GenerateTableFetch.png)

此处没有设置Maximum-value Columns，执行一次，可以进行全量同步。

生产环境中，应设置Maximum-value Columns：AAZ648，可以进行增量同步（第一次增量同步，即全量同步）。



![image-20240611023919165](_media\南昌人社\南昌人社_nifi画布_ExecuteSQLRecord.png)

![image-20240611024001721](_media\南昌人社\南昌人社_nifi画布_PutDatabaseRecord.png)

```SQL for mysql
--SQL语句(for mysql)---使用Nifi演示南昌人社的业务场景

-- 创建数据库
CREATE DATABASE IF NOT EXISTS testdb;
USE testdb;

-- 删除表
DROP TABLE IF EXISTS testdb.wy_ab01_369900;

-- 创建表
CREATE TABLE IF NOT EXISTS testdb.wy_ab01_369900 (
    aab001 VARCHAR(10),
    aab301 VARCHAR(20)
);

-- 插入数据
INSERT INTO testdb.wy_ab01_369900 (aab001, aab301) VALUES
('aa', '3601abcd'),
('bb', '3601efgh'),
('cc', '1234ijkl'),
('dd', '5678mnop'),
('ee', '3601qrst');

-- 验证查询
select aab001 from testdb.wy_ab01_369900 where substr(aab301,1,4) = '3601';

------------------------------------------------------------------------------------
-- 删除表 AC08（如果存在）
DROP TABLE IF EXISTS testdb.AC08;

-- 创建表AC08
CREATE TABLE IF NOT EXISTS testdb.AC08 (
    AAB001 VARCHAR(10),
    AAZ648 INT,
    AAC301 VARCHAR(255),
    AAA027 VARCHAR(255)
);

--插入数据到表 AC08
INSERT INTO testdb.AC08 (AAB001, AAZ648, AAC301, AAA027) 
VALUES
('aa', 100, 'Data 1', '3601abcd'),
('bb', 101, 'Data 2', '3601efgh'),
('cc', 102, 'Data 3', '1234ijkl'),
('dd', 103, 'Data 4', '5678mnop'),
('ee', 104, 'Data 5', '3601qrst'),
('ff', 105, 'Data 6', 'abcd3601'),
('gg', 106, 'Data 7', 'efgh1234'),
('hh', 107, 'Data 8', 'ijkl5678'),
('ii', 108, 'Data 9', 'mnop3601'),
('jj', 109, 'Data 10', 'qrst5678');

------------------------------------------------------------------------------------
--验证查询
SELECT T.* FROM
(
	SELECT AAB001,AAZ648, AAC301, SUBSTR(AAA027, 1, 4) AS AAA027_STR
	FROM testdb.AC08
) t
WHERE 
​	t.AAA027_STR = '3601'
  	OR 
​	t.aab001 in (select aab001 from testdb.wy_ab01_369900 where substr(aab301,1,4) = '3601');

--验证查询
SELECT AAB001,AAZ648, AAC301, SUBSTR(AAA027, 1, 4) 
FROM testdb.AC08
WHERE
	SUBSTR(AAA027, 1, 4) = '3601'
 	OR 
 	aab001 in (select aab001 from testdb.wy_ab01_369900 where substr(aab301,1,4) = '3601');
```



------

#### 产品BUG记录

##### TongETL的 JDBC连接异常断开

问题描述：大表进行分批同步，上一个批次同步完成（入库完成），执行下一个批次的数据查询时，报连接已断开异常。

解决办法：SQL查询组件每次执行查询时，先判断当前使用的JDBC连接是否可用，如果不可用，重新获取JDBC连接。

归因分析：SQL查询组件一直使用同一个数据库连接，当查询返回的结果集过大时，处理该结果集需要耗费10小时左右（插入结果数据集的时间）。执行下一次查询时，因链接长时间空闲，被数据库主动断开。

补充说明：

1、最初，OB省库“默认连接8个小时不活跃，主动断开数据库连接“，目前OB厂商已调整相应参数至24小时。

2、通过上面的方式，并未真正解决问题。某一批次的查询结果集入库时间超过8小时，这是不正常的！需要检查目标数据库的数据库连接池配置、ETL入库的并行度设置，提升入库效率。

##### TongETL的 JDBC查询结果集资源未释放

问题描述：系统内存32G，ETL内存上限设置20G，某次数据同步出现OOM内存溢出，导致TongETL同步任务异常停止。

解决办法：通过内存分析发现查询结果集未释放。在查询组件停止的回调方法中，关闭查询结果集并把查询结果集对象设置为null，从而释放查询结果集。

##### TongETL 无法通过CDC获取数据库隐藏字段

问题描述：TongETL配置CDC增量任务时，无法获取数据库表中的隐藏字段，导致获取的增量数据不全。

解决办法：在TongETL中配置增量数据时，增加隐藏字段输入框，以便获取表字段属性时包含隐藏字段。

归因分析：当数据库字段的属性为INVISIBLE时，TongETL无法获取隐藏字段，配置的CDC增量任务也无法获取隐藏字段。

![image-20240612154602407](_media\南昌人社\ETL_CDC增量抽取.png)

##### TongCDC 解析无主键库表报错

问题描述：江西省人社的OceanBase数据库中，有部分表没有主键。 解析时，TongCDC无法获取主键列，导致程序报NPE异常。

解决办法：TongCDC获取OceanBase无主键表的信息时，将表的唯一索引作为主键。

##### TongCDC 客户端订阅异常导致增量任务终止

问题描述：TongCDC客户端订阅了增量任务中没有配置的表，导致增量任务被终止。

解决办法：
捕获该异常，不向上层抛出，把异常记录到错误日志中。TongCDC客户端提示订阅表不存在。

注：

OBCDC服务程序：调用OB的C语言接口读取日志，写Socket，然后使用JAVA从socket获取数据，并封装成JNI接口（直接封装JNI接口有问题）。

TongCDC服务程序：调用OBCDC服务程序接口（模拟的JNI接口）获取日志数据，转换成文件。

TongCDC客户端程序：从文件中提取数据，绑定某一张表，被绑定表的只能通过该客户端获取数据。

------

#### 产品功能优化

##### 无需重启TongCDC服务，重置已入库数据标记点

问题描述：TongETL在消费TongCDC的增量数据时，如果入库错误（该部分入库数据丢失），需要重启TongCDC服务，重置TongCDC的已消费数据标记点的信息。


解决办法：在对应表的增量数据目录下，增加一个reset_read.dat文件，文件中写入需要重置的标记点信息，在客户端下一次的消费中，就会从重置标记点重新消费数据，不需要再重启TongCDC服务。

##### TongETL的CDC组件增加批次号字段

问题描述：TongETL消费TongCDC的增量数据时，处理失败的组件没有记录TongCDC数据批次号；恢复时，需要人工查询。

解决办法：TongCDC组件在每条增量数据中加入对应的批次号。数据处理失败时，在错误日志中可以找到对应的数据批次号。



------

#### OceanBase数据库问题记录

##### 数据库日志出现断档，无法通过CDC获取增量数据

[2024-05-26 17:17:17.099858] INFO [TLOG] ob_log_instance.cpp:585 [574175][0][YC2DF0A6805E4-0000000000000001-0-0] [lt=5] init liboblog succ(is_schema_split_mode=true, start_tstamp=1716342540000000, start_tstamp="[2024-05-22 09:49:00.000000]", working_mode="Storager Working Mode", err_cb=0x403af0)；

将上面的错误信息发给OB人员进行排查。之后在ob人员的指导下放开日志输出限制，打印更多详细日志，在输出更多的详细日志中发现，在obcdc启动后，日志中一直打印错误信息："start tstamp is too old, can not force-startup when all server is out of lower bound"，然后让ob人员再次确认日志保留天数，发现日志实际保留天数为3天，不是7天。

##### OB数据库连接池不稳定

测试环境中，系统内存扩容到128G，ETL内存上限设置为60G，测试多线程入库，

25个入库线程：出现目标库连接错误类问题；

15个入库线程：出现目标库连接错误类问题；

10个入库线程，可以长时间平稳运行。

以目前的速度，10个线程同时写一张表，一天大约同步2-3亿（上限）。以AC08表20亿数据为例，完成全量同步需要10天左右。



##### 数据库快照太旧

问题描述：ETL查询数据时，省端库报快照太旧的错误。联系OB厂商，对方已将Undo时间设置为两个小时，后续未再次出现此错误。

归因分析：1、数据库执行长时间运行查询时，通常会创建一个一致性快照，以确保查询过程中数据的一致性。这个快照记录了查询开始时的数据状态。2、数据库依赖Undo日志回滚未提交的事务，保持快照的一致性。如果Undo日志的保留时间不足，快照数据会变成不可用，导致“快照太旧”的错误。3、当出现“快照太旧”的错误时，查询无法完成，因为系统无法访问到一致的快照数据。这会中断ETL操作，影响数据提取和转换的进程。

**解决办法**：

1、增加Undo日志的保留时间，比如将其设置为两个小时，以确保查询期间的快照可以被保留更长时间，减少错误的发生。

2、这个问题，虽然通过“增加Undo日志的保留时间”解决了，但是根源上还是查询时间太长导致的。正确的做法：通过优化查询性能，或者降低分页大小，减少查询执行时间，从而降低快照过期的可能性。（一个查询长时间不返回，一定是有问题的。）



------

#### 其他问题记录

##### TongETL进程夜里自行退出，没有报错信息

问题描述：TongETL进程在夜里无故退出，没有任何错误信息，没有自动生成dump文件（OOM发生时），分析手动生成的dump文件，发现所有的任务已停止。打印GC日志的OOM相关信息， linux系统日志中kill进程的相关信息，均无法排查该问题出现的原因。

解决办法：
https://www.cnblogs.com/perfma/p/12467747.html，在网上看到一篇帖子：关闭客户端前，先执行一下CTRL+C。按照帖子的方法，临时解决进程无故消失的问题。之后在查看TongETL的进程信息时，发现TongETL和TongCDC的进程不一样，TongCDC的父进程ID是1，而TongETL的父进程ID不是1，然后查询TongETL的父进程ID，发现TongETL的父进程ID是启动TongETL服务的脚本进程ID。对照TongCDC的启动脚本修改TongETL的启动脚本后，重新执行TongETL的启动脚本，查看TongETL的进程，发现TongETL的父进程ID已变成1，之后就再也没有出现TongETL的父进程无故消失的问题。

归因分析：关闭启动TongETL的Putty客户端，过一段时间，TongETL进程消失。为什么会这样呢？假如我们在shell里运行加了&的脚本，父进程退出，子进程会挂到init进程下（通过ps -ef 查看，父进程是1号进程）。如果父进程不退出，关闭当前窗口，父进程会被强制退出，并给子进程发送SIGHUP信号，最终导致TongETL 进程退出。

##### TongETL进程存在，但是无响应

问题描述：TongETL出现大量入库失败错误，top发现TongETL的进程把分配给它的60G内存占满，而且TongETL的线程存在，但是无响应。日志中除了入库失败的日志，并没有其它错误日志。

解决过程：

1、使用iava自带或者阿里的arthas 工具分析ivm内存，都无法 attach 到TongETL的进程中去获取java进程相关信息。

2、在网上搜索Kettle相关的帖子，说可能是由于Kettle的并发线程抢资源可能引发死锁，但是没有说明死锁发生在哪里以及如何修复----无法确定是否真的存在死锁。

3、还有一个可能的原因，TongETL会把入库失败的数据记录到文件中，这种大量写文件的并发操作可能触发这种问题，之前没有开启多线程并发入库时，并没有出现这种情况。

4、使用gdb工具把当前内存core dump到文件中，留着排查问题使用。

5、重启TongETL服务，继续测试全量同步任务。

6、只出现了一次，目前无定论。

##### TongETL进程堆内存占用不释放

问题描述：运行TongETL任务时，由于并发入库导致市数据库压力过大，TongETL任务插入报错，无法正常运行，任务被停止。任务停止后，发现大量内存未释放（被占用的内存为48G），手动GC之后内存也没有释放。使用imap把ivm内存转储出来，内存转储文件只有8G，使用iprofiler分析发现，堆内存总共8G左右。

问题分析：已修复查询结果集未释放导致的内存占用。top命令中显示TongETL进程占用内存较大，通过阿里的arthas工具发现这几天JVM只执行了一次FULL GC, 堆内存占用58G左右，使用中的16G左右，使用率在30%左右。网上的资料提到：jvm申请内存使用之后，Full GC时不会立即释放内存，而是在系统内存不足或者多次Full GC之后才会把部分空闲的堆内存还给操作系统。所以，堆内存不释放，应该不是程序问题，而是java的一种机制。

最近一次内存记录情况：最大堆内存设置为60G，占用50G，最高使用在30G左右。



##### ETL如何实现自动分页

1、获取最大 ID（或者时间戳，下面以ID为例）
SELECT MAX(id) INTO max_id FROM table_name;

2、分页查询

SELECT * FROM table_name WHERE id <= max_id ORDER BY id LIMIT 10000 OFFSET 0;

SELECT * FROM table_name WHERE id <= max_id ORDER BY id LIMIT 10000 OFFSET 10000;

-- 依此类推，直到提取完所有数据，这一步可以自动生成。

**问题描述：offset数量过大，出现租户内存不足的问题**

问题分析：使用大量的 OFFSET 可能会导致性能问题，特别是在处理大表时，因为数据库需要扫描并跳过前面的记录，这会消耗大量的内存和计算资源。

**优化方案：基于主键或唯一索引分页**

假设 id 是主键或唯一索引列，可以使用以下方式进行分页查询

首次查询：
SELECT * FROM table_name
WHERE id <= max_id
ORDER BY id
LIMIT 10000;

后续查询：使用上次查询的最后一条记录的 id 作为起始点进行下一次查询。

SELECT * FROM table_name
WHERE id > last_id AND id <= max_id
ORDER BY id
LIMIT 10000;



##### 重新启动全量同步任务，无法自动接续

问题描述：在开启增量同步时，不小心停止了AC43大表的同步任务，导致全量同步重新开始。

解决办法：暂时没有找到记录最大值的实现方式；之前也做过一些尝试，没有实现。



------

#### 下一步工作

##### **DXP5.0：实现数据同步的全流程自动化**

将南昌人社的数据同步场景做成标准模板，给模板传递参数，实现数据同步流程的配置、启动、停止。

将所有库表的ETL流程配置信息，整理到一张excel表格中，通过程序自动拉起库表同步任务。



##### 库表全量比对工具

使用CDC进行增量同步时，一旦数据库日志丢失，需要重新进行库表的全量同步、增量同步。为了避免这种情况的发生，需要支持对源库表与目的库表的数据进行全量对比。

以下是可能会造成数据库日志丢失的几种情况：

1. 全量同步所需时间超过日志保存时间，数据库日志会丢失。

2. ETL同步任务的故障时间大于日志保存时间，数据库日志会丢失。

3. 数据库故障时间（无法获取数据库日志）超过日志保存时间，数据库日志会丢失。

4. 开启ETL全量任务时，启动CDC增量日志获取任务，将数据库日志保存到硬盘上。备份日志采取周期删除策略，ETL同步任务的故障时间大于日志删除周期，数据库日志会丢失。

5. 新版DXP支持PUSH，不考虑落盘的方案（不会备份增量日志）。ETL同步任务的故障时间超过数据库的日志保存时间时，数据库日志会丢失。

   

------



